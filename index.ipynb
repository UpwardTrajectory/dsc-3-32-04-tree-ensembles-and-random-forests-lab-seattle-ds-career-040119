{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Ensembles and Random Forests - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll create some popular Tree Ensemble models such as a Bag of Trees and a Random Forest to predict a person's salary based on information about them. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Create, train, and make predictions with Bagging Classifiers\n",
    "* Create, train, and make predictions with a Random Forest\n",
    "* Understand and explain the concept of bagging as it applies to Ensemble Methods\n",
    "* Understand and explain the Subspace Sampling Method and it's use in Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we'll be looking at a dataset of information about people and trying to predict if they make more than 50k/year.  The salary data set was extracted from the census bureau database and contains salary information. The goal is to use this data set and to try to draw conclusions regarding what drives salaries. More specifically, the target variable is categorical (> 50k; <= 50 k). Let's create a classification tree!\n",
    "\n",
    "To get started, run the cell below to import everything we'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is stored in the file `salaries_final.csv`.  \n",
    "\n",
    "In the cell below, read in the dataset from this file and store it in a DataFrame.  Be sure to set the `index_col` parameter to `0`.  Then, display the head of the DataFrame to ensure that everything loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Education       Occupation   Relationship   Race   Sex  \\\n",
       "0           0   39  Bachelors     Adm-clerical  Not-in-family  White  Male   \n",
       "1           1   50  Bachelors  Exec-managerial        Husband  White  Male   \n",
       "\n",
       "  Target  \n",
       "0  <=50K  \n",
       "1  <=50K  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries = pd.read_csv('salaries_final.csv')\n",
    "salaries.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are 6 predictors, and one outcome variable, the target salary <= 50k/ >50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall that the 6 predictors are:\n",
    "\n",
    "- `Age`: continuous.\n",
    "\n",
    "- `Education`: Categorical. Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, \n",
    "Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "- `Occupation`: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "- `Relationship`: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "- `Race`: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "- `Sex`: Female, Male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to store our `'Target'` column in a separate variable and drop it from the dataset.  \n",
    "\n",
    "Do this in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education has 16\n",
      "Occupation has 15\n",
      "Relationship has 6\n",
      "Race has 5\n",
      "Sex has 2\n",
      "Target has 2\n"
     ]
    }
   ],
   "source": [
    "for col in salaries:\n",
    "    cat_count = len(salaries[col].value_counts())\n",
    "    if cat_count < 20:\n",
    "        print(col, 'has', cat_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = salaries['Target'].replace({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll want to confirm that the Age column is currently encoded in a numeric data type, and not a string. By default, pandas will treat all columns encoded as strings as categorical columns, and create a dummy column for each unique value contained within that column.  We do not want a separate column for each age, so let's double check that the age column is encoded as an integer or a float.  \n",
    "\n",
    "In the cell below, check the `.dtypes` of the DataFrame to examine the data type of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Education', 'Occupation', 'Relationship', 'Race',\n",
       "       'Sex', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now we're ready to create some dummy columns and deal with our categorical variables.  \n",
    "\n",
    "In the cell below, use pandas to create dummy columns for each of categorical variables.  If you're unsure of how to do this, check out the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>11th</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Education         Occupation   Relationship   Race     Sex\n",
       "0   39  Bachelors       Adm-clerical  Not-in-family  White    Male\n",
       "1   50  Bachelors    Exec-managerial        Husband  White    Male\n",
       "2   38    HS-grad  Handlers-cleaners  Not-in-family  White    Male\n",
       "3   53       11th  Handlers-cleaners        Husband  Black    Male\n",
       "4   28  Bachelors     Prof-specialty           Wife  Black  Female"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = salaries[['Age', 'Education', 'Occupation', 'Relationship', 'Race', 'Sex']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, split your data and target into training and testing sets using the appropriate method from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's rebuild a \"regular\" tree as a baseline\n",
    "\n",
    "We'll begin by fitting a regular Decision Tree Classifier, so that we have something to compare our ensemble methods to.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Building the tree\n",
    "\n",
    "In the cell below, create a Decision Tree Classifier.  Set the `criterion` to `'gini'`, and a `max_depth` of `5`.  Then, fit the tree to our training data and labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-pandas in /opt/conda/envs/learn-env/lib/python3.6/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (1.16.3)\n",
      "Requirement already satisfied: pandas>=0.11.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (0.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas) (2018.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.11.0->sklearn-pandas) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-pandas\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn_pandas as skp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education_x0_10th</th>\n",
       "      <th>Education_x0_11th</th>\n",
       "      <th>Education_x0_12th</th>\n",
       "      <th>Education_x0_1st-4th</th>\n",
       "      <th>Education_x0_5th-6th</th>\n",
       "      <th>Education_x0_7th-8th</th>\n",
       "      <th>Education_x0_9th</th>\n",
       "      <th>Education_x0_Assoc-acdm</th>\n",
       "      <th>Education_x0_Assoc-voc</th>\n",
       "      <th>Education_x0_Bachelors</th>\n",
       "      <th>...</th>\n",
       "      <th>Relationship_x0_Unmarried</th>\n",
       "      <th>Relationship_x0_Wife</th>\n",
       "      <th>Race_x0_Amer-Indian-Eskimo</th>\n",
       "      <th>Race_x0_Asian-Pac-Islander</th>\n",
       "      <th>Race_x0_Black</th>\n",
       "      <th>Race_x0_Other</th>\n",
       "      <th>Race_x0_White</th>\n",
       "      <th>Sex_x0_Female</th>\n",
       "      <th>Sex_x0_Male</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8369</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Education_x0_10th  Education_x0_11th  Education_x0_12th  \\\n",
       "26464                0.0                0.0                1.0   \n",
       "16134                0.0                0.0                0.0   \n",
       "4747                 0.0                0.0                0.0   \n",
       "8369                 0.0                0.0                0.0   \n",
       "5741                 0.0                0.0                0.0   \n",
       "\n",
       "       Education_x0_1st-4th  Education_x0_5th-6th  Education_x0_7th-8th  \\\n",
       "26464                   0.0                   0.0                   0.0   \n",
       "16134                   0.0                   0.0                   0.0   \n",
       "4747                    0.0                   0.0                   0.0   \n",
       "8369                    0.0                   0.0                   0.0   \n",
       "5741                    1.0                   0.0                   0.0   \n",
       "\n",
       "       Education_x0_9th  Education_x0_Assoc-acdm  Education_x0_Assoc-voc  \\\n",
       "26464               0.0                      0.0                     0.0   \n",
       "16134               0.0                      0.0                     0.0   \n",
       "4747                0.0                      0.0                     0.0   \n",
       "8369                0.0                      0.0                     0.0   \n",
       "5741                0.0                      0.0                     0.0   \n",
       "\n",
       "       Education_x0_Bachelors ...   Relationship_x0_Unmarried  \\\n",
       "26464                     0.0 ...                         0.0   \n",
       "16134                     0.0 ...                         0.0   \n",
       "4747                      0.0 ...                         0.0   \n",
       "8369                      0.0 ...                         0.0   \n",
       "5741                      0.0 ...                         0.0   \n",
       "\n",
       "       Relationship_x0_Wife  Race_x0_Amer-Indian-Eskimo  \\\n",
       "26464                   0.0                         0.0   \n",
       "16134                   0.0                         0.0   \n",
       "4747                    0.0                         0.0   \n",
       "8369                    0.0                         0.0   \n",
       "5741                    0.0                         0.0   \n",
       "\n",
       "       Race_x0_Asian-Pac-Islander  Race_x0_Black  Race_x0_Other  \\\n",
       "26464                         0.0            1.0            0.0   \n",
       "16134                         0.0            0.0            0.0   \n",
       "4747                          0.0            0.0            0.0   \n",
       "8369                          0.0            0.0            0.0   \n",
       "5741                          0.0            0.0            0.0   \n",
       "\n",
       "       Race_x0_White  Sex_x0_Female  Sex_x0_Male  Age  \n",
       "26464            0.0            0.0          1.0   59  \n",
       "16134            1.0            1.0          0.0   71  \n",
       "4747             1.0            0.0          1.0   42  \n",
       "8369             1.0            0.0          1.0   26  \n",
       "5741             1.0            0.0          1.0   46  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This \"gen_features\" just builds a properly formatted list to pass in to skp.DataFrameMapper()\n",
    "when we want to apply the same function to multiple columns.\n",
    "\n",
    "OneHotEncoder needs df, not series, so we pass a list of single item lists.\n",
    "'''\n",
    "define_features = skp.gen_features(\n",
    "    columns=[['Education'], ['Occupation'], ['Relationship'], ['Race'], ['Sex']],  \n",
    "    classes=[OneHotEncoder]\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "The commented out top line will do nothing to \"Age\" but importantly, it WILL keep it in \n",
    "the front column of df_out. This is also possible by passing in the \"default=None\" parameter\n",
    "which is different from the default behaviour: \"default=False\". (Although the \"Age\" column will \n",
    "be the final column instead of the front using the parameter option.) \n",
    "'''\n",
    "one_hot_map = skp.DataFrameMapper(\n",
    "    #[('Age', None)] +\n",
    "    define_features,\n",
    "    df_out=True, default=None)\n",
    "\n",
    "data_train_out = one_hot_map.fit_transform(data_train)\n",
    "data_train_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = skp.pipeline.Pipeline([\n",
    "    ('one hot', one_hot_map),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('one hot', DataFrameMapper(default=None, df_out=True,\n",
       "        features=[(['Education'], [OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)]), (['Occupation'], [OneHotEncoder(categorical_f...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree_clf = None\n",
    "pipe.fit(data_train, y=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957253408672154"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature importance\n",
    "\n",
    "Let's quickly examine how important each feature ended up being in our Decision Tree model.  Check the `feature_importances_` attribute of our trained model to see what it displays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_names() missing 3 required positional arguments: 'columns', 'transformer', and 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-599b4c388b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'one hot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_names() missing 3 required positional arguments: 'columns', 'transformer', and 'x'"
     ]
    }
   ],
   "source": [
    "model = pipe.named_steps['model']\n",
    "one_hot = pipe.named_steps['one hot']\n",
    "one_hot.get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That matrix isn't very helpful, but a visualization of the data it contains could be.  Run the cell below to plot a visualization of the feature importances for this model. Run the cell below to create a visualization of the data stored inside of a model's `.feature_importances_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_feature_importances(model):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(model.n_features_), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(model.n_features_), model.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model performance\n",
    "\n",
    "Next, let's see how well our model performed on the data. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Use the classifier to create predictions on our test set. \n",
    "* Print out a `confusion_matrix` of our test set predictions.\n",
    "* Print out a `classification_report` of our test set predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the model's accuracy. Run the cell below to display the test set accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy for Decision Tree Classifier: {:.4}%\".format(accuracy_score(target_test, pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bagged trees\n",
    "\n",
    "The first Ensemble approach we'll try is a Bag of Trees.  This will make use of **_Bagging_**, along with a number of Decision Tree Classifier models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a `BaggingClassifier`.  In the first parameter spot, initialize a `DecisionTreeClassifier` and set the same parameters that we did above for `criterion` and `max_depth`.  Also set the `n_estimators` parameter for our Bagging Classifier to `20`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, fit it to our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of a model is such a common task that all (supervised learning) models contain a `score()` method that wraps the `accuracy_score` helper method we've been using.  All we have to do is pass it a dataset and the corresponding labels and it will return the accuracy score for those data/labels.  \n",
    "\n",
    "Let's use it to get the training accuracy of our model. In the cell below, call the `.score()` method on our Bagging model and pass in our training data and training labels as parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the accuracy score that really matters--our testing accuracy.  This time, pass in our testing data and labels to see how the model did.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random forests\n",
    "\n",
    "Another popular ensemble method is the **_Random Forest_** model.  Let's fit a Random Forest Classifier next and see how it measures up compared to all the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fitting a random forests model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a `RandomForestClassifier`, and set the number estimators to `100` and the max depth to `5`. Then, fit the model to our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the training and testing accuracy of the model using its `.score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Look at the feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \"relationship\" represents what this individual is relative to others. For example an\n",
    "individual could be a Husband. Each entry only has one relationship, so it is a bit of a weird attribute.\n",
    "\n",
    "Also note that more features show up. This is a pretty typical result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Look at the trees in your forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a forest with some small trees. You'll learn how to access trees in your forest!\n",
    "\n",
    "In the cell below, create another `RandomForestClassifier`.  Set the number of estimators to 5, the `max_features` to 10, and the `max_depth` to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_2 = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making `max_features` smaller will lead to very different trees in your forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trees in your forest are stored in the `.estimators_` attribute.\n",
    "\n",
    "In the cell below, get the first tree from `forest_2.estimators_` and store it in `rf_tree_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tree_1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reuse ourn `plot_feature_importances` function to visualize which features this tree was given to use duing subspace sampling. \n",
    "\n",
    "In the cell below, call `plot_feature_importances` on `rf_tree_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, grab the second tree and store it in `rf_tree_2`, and then pass it to `plot_feature_importances` in the following cell so we can compare which features were most useful to each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tree_2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see by comparing the two plots that the two trees we examined from our Random Forest look at different attributes, and have wildly different importances for them!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we got some practice creating a few different Tree Ensemble Methods. We also learned how to visualize feature importances, and compared individual trees from a Random Forest to see if we could notice the differences in the features they were trained on. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
